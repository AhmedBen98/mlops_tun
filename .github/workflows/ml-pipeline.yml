name: ML Pipeline CI/CD

on:
  push:
    branches: [ master, develop, dataset-* ]
  pull_request:
    branches: [ master ]
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.10'

jobs:
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    env:
      MLFLOW_TRACKING_URI: ./mlruns
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov
      - name: Run unit tests
        run: |
          pytest tests/ -v --cov=src --cov-report=xml --cov-report=html
      - name: Upload coverage reports
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
          flags: unittests
          name: codecov-umbrella

  data-validation:
    name: Validate Data
    runs-on: ubuntu-latest
    needs: test
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: DVC pull data
        run: |
          pip install dvc
          dvc pull --force || true
      - name: Validate data schema
        run: |
          python -c 'import pandas as pd; import sys; df = pd.read_csv("data/raw/mlops_dataset_original.csv"); print(f"Dataset shape: {df.shape}"); print(f"Columns: {list(df.columns)}"); sys.exit(1) if df.empty else None; print(f"WARNING: Found {df.isnull().sum().sum()} missing values") if df.isnull().sum().sum() > 0 else None; print("Data validation passed!")'

  ml-pipeline:
    name: Run ML Pipeline
    runs-on: ubuntu-latest
    needs: data-validation
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Debug params.yaml
        run: |
          pwd
          ls -l
          ls -l params.yaml || echo "params.yaml NOT FOUND"
      - name: Run data processing
        continue-on-error: true
        run: |
          PYTHONPATH=. python3 src/data_processing.py --input data/raw/mlops_dataset_v3.csv --output data/processed --params params.yaml
      - name: Run feature engineering
        run: |
          PYTHONPATH=. python3 src/feature_engineering.py --train data/processed/train.csv --val data/processed/val.csv --test data/processed/test.csv --output data/processed --params params.yaml
      - name: Train model
        run: |
          PYTHONPATH=. python3 src/train.py --train data/processed/train_engineered.csv --val data/processed/val_engineered.csv --output models --params params.yaml
      - name: Evaluate model
        run: |
          PYTHONPATH=. python3 src/evaluate.py --test data/processed/test_engineered.csv --model models/model.pkl --output metrics --params params.yaml
      - name: Upload metrics
        uses: actions/upload-artifact@v4
        with:
          name: ml-metrics
          path: |
            metrics/
            plots/
      - name: Upload model
        uses: actions/upload-artifact@v4
        with:
          name: trained-model
          path: models/

  compare-models:
    name: Model Comparison Report
    runs-on: ubuntu-latest
    needs: ml-pipeline
    if: github.event_name == 'pull_request'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Download metrics
        uses: actions/download-artifact@v4
        with:
          name: ml-metrics
          path: metrics/
      - name: Generate comparison report
        run: |
          echo "## Model Performance Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f "metrics/test_metrics.json" ]; then
            echo "### Test Metrics" >> $GITHUB_STEP_SUMMARY
            echo '```json' >> $GITHUB_STEP_SUMMARY
            cat metrics/test_metrics.json >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
